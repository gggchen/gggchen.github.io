<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>notes on G Chen</title>
    <link>http://gggchen.github.io/tags/notes/</link>
    <description>Recent content in notes on G Chen</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2019 Chen</copyright>
    <lastBuildDate>Sat, 04 Jan 2020 00:00:00 +0100</lastBuildDate>
    
	<atom:link href="http://gggchen.github.io/tags/notes/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>2019 读书总结</title>
      <link>http://gggchen.github.io/post/books2019/</link>
      <pubDate>Sat, 04 Jan 2020 00:00:00 +0100</pubDate>
      
      <guid>http://gggchen.github.io/post/books2019/</guid>
      <description>Fluent forever 不仅介绍了学语言的规律而且总结了如何学习.
比如推荐了分辨语言中难易辨别音的方法, 之前我从来没有搞明白过德语的 e 和 i 有什么区别, 我尝试用他介绍的方法, 把这两个音放在 Anki 卡片里, 听音做选择, 并没有收获. 后来看又看了一些资料终于明白了.
还介绍了怎么背单词, 当然是利用类似 Anki 的卡片间隔重复记忆, 关键是他总结了一套记单词的一套工作流程. 我真的服气了, 我本来想写个博客来介绍我的背单词流程, 和这本书一比起来就是 nothing, 他也早写好博客 并且做好视频教程了, 甚至还有配套的 Anki 的模板, 在 Download and install my model deck 中可以找到下载.
 用 Eudic 等词典查单词意思以及音标 利用 https://forvo.com/ 下载单词发音 谷歌搜索这个单词相关的图片, 因为大脑更容易记住图形 然后在 Anki 里面背单词, 自动规律间断重复  另外一个收获是, 一张卡片最好只记忆一个东西. 单词有时有几个记忆点时, 我应该把单词分开背, 一次只背一项. 现在我背德语, 一张卡片记忆德语对应的含义, 第二张卡片记忆含义对应的德语, 第三张卡片记忆该德语名词的复数, 这样不会盯着一张卡片想完成三个动作, 然后崩溃, 再也不想背了. 我之前很多次痛苦的学习记忆就是一张卡片想背的东西太多.
《娱乐至死》 这本书写了电视的出现对书本作为传播媒介的影响, 技术从来不是中立的, 技术和工具会束缚限制塑造我的思维</description>
    </item>
    
    <item>
      <title>朗读者</title>
      <link>http://gggchen.github.io/post/the-reader/</link>
      <pubDate>Fri, 23 Mar 2018 00:00:00 +0100</pubDate>
      
      <guid>http://gggchen.github.io/post/the-reader/</guid>
      <description>读了《朗读者》小说, 发现了一些电影中没有说明的细节.
剧情 十五岁的学生米夏在回家路上偶遇了三十六岁的汉娜, 两个人成为情人. 米夏每天放学先去去汉娜家给汉娜读书, 然后两人洗澡, 做爱. 汉娜在一天突然离开, 米夏很久之后才把汉娜忘掉, 却再也没法爱别人.
米夏进了大学读法律, 再次看到汉娜是二战之后在法庭上, 汉娜作为关押犹太人的看守而被审判. 汉娜被指控终身监禁. 米夏后来一直继续为汉娜朗读小说, 把录音的磁带寄给狱中的汉娜. 汉娜在出狱前一天在狱中自杀.
阶级 电影只让我感觉这是一段在年龄上悬殊的感情, 小说中细致描写了双方的家庭, 让我意识到这段感情在阶级上也是很不匹配的. 汉娜是一个底层文盲, 米夏是高级知识分子的家庭.
汉娜不识字, 经历坎坷, 十七岁去柏林, 在西门子做女工, 参加了一战, 战争后找了所有能干的工作, 认识米夏的时候在做公交车检票员这种简单工作.
而米夏的父亲是一位哲学教授, 白天有学生排着队找他请教问题. 家里有着丰富的藏书, 他父亲自己还出过书.
看电影的时候, 我把自己想象成的是米夏, 一个男性角色. 读小说看到汉娜这么坎坷的经历, 能更多代入汉娜这个角色. 汉娜第一次来到米夏的家里, 看到他家有一面墙的藏书. 汉娜和米夏出去玩, 只能依赖米夏找餐馆点菜住宿, 这种无助的底层角色刚到大城市两眼一抹瞎的状态让我很代入, 我也羡慕别人能在家里有一面墙的藏书. 也想起了自己从村里到城市的大开眼界, 第一次出国住宿时候的茫然无措.
情侣的误会 电影里也有汉娜和米夏的吵架, 吵得莫名其妙, 读了小说才明白.
汉娜是公交车剪票员, 米夏拐去搭乘她那一班公交车. 公车有两节, 两节都没有乘客, 前一节有司机, 所以米夏想单独和汉娜相处, 就一直呆在第二节车厢. 但是汉娜迟迟不来找自己, 和司机聊天. 米夏很生气, 自己专门来看她, 她却不理自己, 后来在一个荒凉地方下车了, 哭着走回去.而汉娜是不懂米夏想和她单独相处才没去找她, 可能也是为自己干这么简单的工作而不好意思了, 以为米夏不来第一节车厢找自己因为自己的工作太傻了. 这两个人才互相在乎而互相生气.</description>
    </item>
    
    <item>
      <title>《女性主义》读书笔记</title>
      <link>http://gggchen.github.io/post/feminism/</link>
      <pubDate>Thu, 08 Mar 2018 00:00:00 +0100</pubDate>
      
      <guid>http://gggchen.github.io/post/feminism/</guid>
      <description>听说女权主义内部也是有众多流派的, 去年读了李银河的《女性主义》, 做了读书笔记, 今天整理一下. 因为从小在一个男权社会里生长, 难免潜移默化受到男权的价值观影响, 了解一下女权主义能更 liberal 一点. 而且李银河这本书挺学术地介绍了女权主义的各个流派, 介绍了各个流派的主要代表人物和思想, 相互的争执的点. 这本书是不错的女权主义的入门书籍, 推荐.
王小波写道, 这本书本来书名为《女权主义》, 但是审查部门不准许出现「女权」的字眼, 为了出版, 只好将 feminism 翻译为「女性主义」. 所以下面不沿用书中被审查后的字眼, 仍然采用「女权主义」称为各个流派.
全文都是对书中内容的引用, 分为两部分, 对一些议题的看法和女权主义的流派介绍.
男女区别 女权主义对于男女是否有差别, 也有不同的看法, 可以分为三种:
 强调男女相同: 男女平等, 两性的相似点超过不同点. 强调男女不同: 女性优于男性, 女性所具有的女性特征比如和平, 关爱, 养育等优于攻击好战毁灭等男性特征. 男女差别的无必要: 混淆两性界限, 人的差异并不足以产生对立两分的结果. 克服心灵、身体的两分, 身体是可变的, 不是不可变.  生育 一些女权主义者反对强加在女性身上的生育义务的. 比如波伏娃说, 一个人并非生下来就是女人, 而是变成女人的. 母性是使女性成为奴隶的最技巧的方法. 只要人们仍然认为女性的主要工作是养育小孩, 女性便不会投身政治、科技. 她们也便不会怀疑男人的优越性. 我们几乎不可能告诉女性洗碗是她们的神圣任务, 于是告诉她们养育孩子是她们的神圣任务.
费尔斯通 认为生育机制是女性受压迫的根源. 女性的生育功能造成两性不平等. 在孕产期, 女人的基本生活来源要依赖男人, 而人类婴儿有很长的育婴期, 这也导致了女性对男性的依赖. 她提出解决办法: 技术改造生育机制, 使生育得以在体外进行.
其他人也列举的不生育的好处:
 女性有更多时间过自己生活; 生育不应该决定女性的生活, 女性应当对自己的生活做出个人的决定.</description>
    </item>
    
    <item>
      <title>learn how to learn</title>
      <link>http://gggchen.github.io/post/learn_motivate/</link>
      <pubDate>Tue, 06 Dec 2016 00:00:00 +0100</pubDate>
      
      <guid>http://gggchen.github.io/post/learn_motivate/</guid>
      <description>以前对于如何学习有着不很系统的, 基于我自己经验的了解, 学习了 C站上的learn how to learn 课程之后, 才知道学习背后的生理上和心理上的原因, 还改变了之前一些错误的认识, 像以为通宵熬夜学习是学习的好方法.
强烈推荐跟着学一下这门课.
chunks 什么是 chunk? 大脑形成的一群相互连接的神经元, 所以能够顺利完成一系列动作. 最好的 chunk 是这样, 一旦这个chunk 形成了, 不需要记住所有细节, 下意识就可以完成一个动作. 《倚天屠龙记》中赵敏找武当的麻烦, 张无忌需要短时间跟张三丰学会太极剑, 张无忌临时学了然后又自己演练了一会, 张三丰问他还记得多少, 张无忌说还记得一两招, 张三丰就等无忌又练了一段, 最后张无忌回答说他已经完全忘记了, 张三丰说你可以上了.
 例子  学习的过程是循序渐进的, 最开始是小的 chunk, 最后小 chunk 连起来形成大的 chunk
 通过学习一门新语言, 比如日语, 从50音图开始, 学习语音语调, 掌握词汇, 后来能够根据情景流畅地说出一个句子. 学会骑自行车之后, 就能协调地在平衡的情况下蹬脚蹬. 弹吉他, 先练习指法, 练习一个个片段, 最后熟练弹奏一段曲子 学数学, 最开始试图解答一个问题, 需要的认知负荷很大, 最好先用例子明白核心和背后的原则, 然后再看概念. 类似先依照地图走到想去的地方, 最后自己不需要地图也能够走到. 熟悉例子之后, 思考为什么每一步要这样走, 为什么在这个时候走这一步.  怎样形成 chunk? 怎样形成一个 chunk, 不管是体育训练肌肉记忆, 还是思维训练解决一个问题, 都是类似的:</description>
    </item>
    
    <item>
      <title>中年男人的放飞自我</title>
      <link>http://gggchen.github.io/post/comeing_up_for_air/</link>
      <pubDate>Thu, 06 Oct 2016 00:00:00 +0200</pubDate>
      
      <guid>http://gggchen.github.io/post/comeing_up_for_air/</guid>
      <description>&lt;p&gt;人在任何时候都会危机, 其中中年危机好像尤为明显. 最近读了两本中年危机追寻人生意义的小说, 一本是毛姆的《月亮和六便士》, 另一本是乔治奥威尔的《上来透口气》. 乔治奥威尔完胜, 我很喜欢这本小说, 也很推荐阅读.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>机器学习中的线性回归</title>
      <link>http://gggchen.github.io/post/ml-regression/</link>
      <pubDate>Thu, 06 Oct 2016 00:00:00 +0200</pubDate>
      
      <guid>http://gggchen.github.io/post/ml-regression/</guid>
      <description>模型 hypothesis $$ h_{\theta}= \theta X = {\sum}_{i=1}^{n} x_i&amp;rsquo; \theta $$
其中：
X is a m x n matrix n is the number of the features m is the number of training examples.  gradient \[ \theta_j :=\theta_j- \alpha \frac{\partial}{\partial \theta_j} J(\theta_j) \] 写成矩阵形式即： \[ \theta := \theta - \alpha X^T(X \theta - y) \]
cost function: \[ J(\theta) = \frac12 {(X \theta - y)}^T (X \theta - y) = \frac12 \sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})^2 \]</description>
    </item>
    
    <item>
      <title>阅读GRE文章的正确姿势</title>
      <link>http://gggchen.github.io/post/gre_reading/</link>
      <pubDate>Thu, 13 Aug 2015 00:00:00 +0200</pubDate>
      
      <guid>http://gggchen.github.io/post/gre_reading/</guid>
      <description>阅读做题的步骤  看长阅读还是短阅读 看看题目数目 看看第一题 读文章＋7原则＋做骨架＋找中心 做题 general题目还是detail  做题的姿势  桉顺序做题 遇到难题排除 实在不行猜一个，不要留着以后做 mark一下 有空回头看看  排除法的标记：
A. X B. √ C. ~  如何正确地读 要关注结构，积极高效地读：最开始读得慢，抓住重点，后来读得快。先看题目再在原文中找，或者太抓细节都是不高效的方式。
七原则
 投入：a 哄自己开心：“太好了，下面6分钟我可以了解一下海啸。”b 辨别好坏，如果海洋受到A的威胁，对A生气，这个坏家伙！ 找简单故事：几个字概括 读→大脑形成图像 正在读的和刚读过的联系起来：支持还是反对，有无回答之前的问题 注意信号：分段和信号词 加快速度别陷入细节，除了：段落开头，Big Surprise, Big Result  ** Point 是核心**
我：不加分辨地读全文→做题→被难题困住→读文章→随便猜一个
更好：抓住文章结构
短文章 一道题：快速读后选
3道题：理解文章
** 做笔记**
 每段中心 Big Suprise Big Result 读完后找全文中心  长文章  首段细细读 剩下段落找中心以及在全文中的作用，细节略去，需要时再读细节。 别读细节，还会起反作用，不仅理解不了中心，而且细节题靠记忆不靠谱，还得回文定位才好 读完找中心  题型 general questions 不用读文章，直接做题</description>
    </item>
    
    <item>
      <title>亚马逊的推荐系统</title>
      <link>http://gggchen.github.io/post/recommendations/</link>
      <pubDate>Sun, 09 Aug 2015 00:00:00 +0200</pubDate>
      
      <guid>http://gggchen.github.io/post/recommendations/</guid>
      <description>协作型过滤collaborative filtering 对一大群人进行搜索，并从中找出与我们品味相近的一小群人。
搜集偏好 对于python，是使用一个嵌套的字典，大型网站可建立数据库
对相似度评价 欧几里德距离：在坐标轴中的距离
皮尔逊相关度：即使一个人比另一个人对同一个物品评分都高，但是高的程度一致，也认定是相关。
其他相关方法：jaccard系数或曼哈顿距离算法还有其他算法都行，只要以一个浮点数作为返回值，而且数值越大相似度越大。最后会看到采用什么相似度评价方法，对结果影响不大。
推荐物品 需要利用已有用户的加权来对目标用户进行推荐，也就是对目标用户没有看的电影进行打分，加权的方式是： 假设 $ P_i $ 是其他用户，$ P_i $ 和目标用户的相似度是$ s_i $，$ X_i $是目标用户没看过的电影，$ P_i $对$ X_i $的打分为$ M_i $，那么对$ X_i $ 的打分$ R_i $可以表示为：
$$ R_i = \frac{\sum M_i s_i}{\sum si}$$
接下来根据目标用户所有没看过的电影，按照打分$ R_i $进行排序，分高的优先推荐。
求和的是刚好看过目标客户没看过的这部电影的其他用户数。
匹配商品 上述方法称为基于用户的协作型过滤(user-based collaborative filtering)，对于像Amazon这样存在上百万客户的大型网站，对每个用户和其他用户比较，再对每位用户评过分的商品比较，速度可能很慢；而且商品过多，用户偏好方面彼此很少会有重叠，用户相似性难以判断。所以要使用另外的方法，称为基于物品的协作型过滤(item-based collaborative filtering)可以将大量计算任务预先执行，能够更快地推荐。物品间变化不像用户间比较那么频繁，不需要不停计算每样物品相似的其他物品，可以将计算安排在网络流量不大的时候进行，或者独立于主应用之外的另一台计算机单独进行。
根据人群对某两件商品的评分确定两件商品的相关系数，负数表示喜欢一件商品会存在讨厌另一件商品的倾向。根据相关系数建立每一件商品和其他商品的相似度列表数据集。
目标客户看过的电影$ Y_i $评分为$ M_i $，没看过的电影$ X_i $ 和$ Y_i $的相似度为$ s_i $，对$ X_i $的评分为$ R_i $:
$$R_i = \frac{\sum M_i s_i} {\sum s_i} $$</description>
    </item>
    
  </channel>
</rss>